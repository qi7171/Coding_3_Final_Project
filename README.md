# DCGAN Style Transfer
The goal of this project is to train a Deep Convolutional Generative Adversarial Network (DCGAN) to generate portrait paintings. After generating, I apply abstract art style transfer techniques to the generated portraits. 

Colab: https://colab.research.google.com/drive/13pHFgujf8P33GUtKZbDkJ6a_ifJAtpJm?usp=sharing


### Dataset used:
Portrait: https://www.kaggle.com/datasets/deewakarchakraborty/portrait-paintings

abstract art style: https://www.kaggle.com/datasets/greg115/abstract-art

abstract art checkpoints: https://www.kaggle.com/datasets/therealcyberlord/abstract-art-generation-dcgan-checkpoints

### Code References:
DCGAN: https://www.kaggle.com/code/therealcyberlord/abstract-art-generation-dcgan

Neural style transfer: https://www.kaggle.com/code/sayakdasgupta/neural-style-transfer-using-vgg19

Debugging and proofreading code: ChatGPT


## Design and development processes

### Train DCGAN
![real image](https://github.com/qi7171/Coding_3_Final_Project/assets/72468017/412ca40e-c001-4de6-aace-831597003300)
For dataset preparation, I modified the DCGAN code to work with a dataset of portrait paintings instead of the original abstract generation dataset. I faced difficulties with dataset changing, it's crucial to ensure that the chosen dataset is properly formatted and contains a sufficient number of portrait paintings for effective training.

After making modifications to the DCGAN code, I trained the model using the portrait paintings dataset. ChatGPT helped me analyse the existing code, identify potential errors, and provide suggestions for debugging.

During the training process, I saved the generated fake images from the DCGAN into a folder. This allows me to analyze and evaluate the quality of the generated images later on.


### Style Transfer
![styletransfer](https://github.com/qi7171/Coding_3_Final_Project/assets/72468017/cbfcdec6-e197-4c27-a194-d512387a4f4c)

Once the DCGAN training is complete, I have a collection of generated fake images, I applied neural style transfer using a pre-trained VGG19 model. The style transfer process involves combining the content of the generated images with the abstract art style from the style dataset.

The final result of applying style transfer to the generated fake images is a set of images that combine the content of the portraits with the abstract art style, creating unique and visually appealing outputs.


## Challenges encountered
DCGAN and style transfer models require substantial computational power and memory. Working with high-resolution images results in longer training times or potential resource limitations.

The number of epochs can indeed influence the resolution and quality of the images generated by DCGAN and style transfer models. I trained the model with a higher number of epochs allowing it to learn more complex features and patterns from the training data, potentially resulting in higher-resolution outputs. As training progresses, the model refines its representations and generates images with improved details and sharper features. Therefore, running the training for more epochs, such as 150 epochs compared to just 10 epochs, gives the model more opportunities to converge to better solutions and generate higher-quality images.

However, it's worth noting that simply increasing the number of epochs doesn't guarantee better results. Finding the most optimised number of epochs is important.


